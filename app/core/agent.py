"""
Agente principal do chatbot de folha de pagamento
Implementa l√≥gica de decis√£o entre RAG, Web Search e conversa geral
"""
import logging
from typing import Dict, Any, Optional

from .llm import LLMConfig
from ..tools.payroll_rag import PayrollRAG
from ..tools.web_search import WebSearch
from .conversation_memory import ConversationMemory

logger = logging.getLogger(__name__)

class PayrollAgent:
    """Agente principal que decide qual ferramenta usar"""
    
    def __init__(self):
        """Inicializa o agente"""
        self.llm = LLMConfig()
        self.rag = PayrollRAG()
        self.web_search = WebSearch()
        self.memory = ConversationMemory()
        
        # Palavras-chave para classifica√ß√£o de consultas
        self.rag_keywords = [
            "funcion√°rio", "funcion√°rios", "sal√°rio", "sal√°rios", "folha", "pagamento",
            "nome", "cargo", "departamento", "data", "valor", "total", "m√©dia", "soma",
            "quem", "quanto", "quando", "onde", "qual", "recebi", "recebeu", "ganhou",
            "l√≠quido", "l√≠quida", "bruto", "bruta", "desconto", "descontos", "inss",
            "irrf", "b√¥nus", "bonus", "trimestre", "semestre", "compet√™ncia"
        ]
        
        self.web_keywords = [
            "lei", "legisla√ß√£o", "direito", "direitos", "trabalhista", "trabalhistas",
            "clt", "fgts", "inss", "imposto", "tributo", "encargo", "encargos",
            "como calcular", "como funciona", "o que √©", "quando", "prazo", "prazo",
            "selic", "taxa", "juros", "f√©rias", "ferias", "13¬∫", "13", "sal√°rio"
        ]
        
        self.general_keywords = [
            "ol√°", "oi", "bom dia", "boa tarde", "boa noite", "obrigado", "obrigada",
            "tchau", "at√© logo", "como voc√™ est√°", "como est√°", "ajuda", "help",
            "tudo bem", "beleza", "ok", "certo", "entendi", "perfeito", "legal",
            "bacana", "show", "massa", "top", "massa", "bacana", "show", "massa",
            "como vai", "e a√≠", "eae", "e a√≠", "beleza", "tranquilo", "suave",
            "valeu", "brigado", "brigada", "obrigad", "obrigad", "valeu", "brigado",
            "at√© mais", "at√©", "tchau", "falou", "flw", "abra√ßo", "abra√ßos",
            "conversa", "falar", "falei", "disse", "comentou", "mencionou",
            "lembra", "lembro", "lembrar", "esqueci", "esqueceu", "esquecer",
            "sabia", "sabia", "sabe", "saber", "conhece", "conhecer", "conhecia",
            "pode", "poder", "consegue", "conseguir", "quero", "quer", "querer",
            "preciso", "precisa", "precisar", "gostaria", "gostaria", "gostar",
            "d√∫vida", "duvida", "duvido", "duvidar", "pergunta", "perguntar",
            "quest√£o", "questao", "quest√£o", "questao", "problema", "problema",
            "solu√ß√£o", "solucao", "solu√ß√£o", "solucao", "resolver", "resolver",
            "explicar", "explicar", "explica√ß√£o", "explicacao", "explica√ß√£o", "explicacao"
        ]
    
    async def process_query(self, message: str, session_id: Optional[str] = None) -> Dict[str, Any]:
        """
        Processa consulta do usu√°rio
        
        Args:
            message: Mensagem do usu√°rio
            session_id: ID da sess√£o (opcional)
            
        Returns:
            Resposta processada
        """
        try:
            # Cria sess√£o se n√£o existir
            if session_id is None:
                session_id = self.memory.create_session()
            
            # Adiciona mensagem do usu√°rio √† mem√≥ria
            self.memory.add_message(session_id, "user", message)
            
            # Analisa o tipo de consulta
            query_type = await self._analyze_query_type(message)
            
            # Obt√©m contexto da conversa
            context = self.memory.get_context_summary(session_id)
            
            # Processa consulta baseada no tipo
            if query_type == "rag":
                result = await self._process_rag_query(message, context)
            elif query_type == "web":
                result = await self._process_web_query(message, context)
            else:
                result = await self._process_general_query(message, context)
            
            # Adiciona resposta √† mem√≥ria
            self.memory.add_message(
                session_id, 
                "assistant", 
                result["response"],
                tool_used=result["tool_used"],
                evidence=result.get("evidence")
            )
            
            # Atualiza contexto
            self.memory.update_context_data(session_id, "last_query_type", query_type)
            self.memory.update_context_data(session_id, "last_tool_used", result["tool_used"])
            
            return result
            
        except Exception as e:
            logger.error(f"Erro ao processar consulta: {e}")
            return {
                "response": f"Desculpe, ocorreu um erro ao processar sua consulta: {str(e)}",
                "evidence": None,
                "tool_used": "error"
            }
    
    async def _analyze_query_type(self, message: str) -> str:
        """
        Analisa o tipo de consulta
        
        Args:
            message: Mensagem do usu√°rio
            
        Returns:
            Tipo de consulta (rag, web, general)
        """
        message_lower = message.lower()
        
        # Verifica palavras-chave RAG (dados espec√≠ficos)
        rag_score = sum(1 for keyword in self.rag_keywords if keyword in message_lower)
        
        # Verifica palavras-chave Web (legisla√ß√£o)
        web_score = sum(1 for keyword in self.web_keywords if keyword in message_lower)
        
        # Verifica palavras-chave gerais (conversa)
        general_score = sum(1 for keyword in self.general_keywords if keyword in message_lower)
        
        # Verifica se √© uma pergunta direta sobre dados espec√≠ficos
        if any(name in message_lower for name in ['ana', 'bruno', 'souza', 'lima']):
            return "rag"
        
        # Verifica se √© uma pergunta sobre legisla√ß√£o
        if any(word in message_lower for word in ['lei', 'direito', 'trabalhista', 'clt', 'fgts', 'inss', 'como calcular', 'como funciona', 'selic', 'taxa selic', 'juros', 'f√©rias', 'ferias', 'previd√™ncia', 'previdencia']):
            return "web"
        
        # Verifica se √© uma conversa geral
        if general_score > 0 or len(message.split()) <= 3:
            return "general"
        
        # Se tem palavras-chave RAG, prioriza RAG
        if rag_score > 0:
            return "rag"
        
        # Se tem palavras-chave Web, prioriza Web
        if web_score > 0:
            return "web"
        
        # Fallback: se n√£o consegue classificar, tenta RAG primeiro
        return "rag"
    
    async def _process_rag_query(self, message: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """
        Processa consulta RAG
        
        Args:
            message: Mensagem do usu√°rio
            context: Contexto da conversa
            
        Returns:
            Resposta processada
        """
        try:
            # Executa consulta RAG
            rag_result = await self.rag.query(message)
            
            if not rag_result["success"]:
                # Usa LLM para gerar resposta mais fluida mesmo quando n√£o encontra dados
                rag_data = rag_result["data"]
                llm_response = await self.llm.generate_response(
                    f"O usu√°rio perguntou: '{message}'. "
                    f"Baseado nos dados dispon√≠veis, a resposta √©: '{rag_data}'. "
                    f"Transforme isso em uma resposta conversacional e amig√°vel.",
                    context
                )
                return {
                    "response": llm_response,
                    "evidence": None,
                    "tool_used": "rag"
                }
            
            # Usa LLM para tornar a resposta mais fluida e conversacional
            rag_data = rag_result["data"]
            evidence = rag_result.get("evidence", [])
            
            try:
                # Monta contexto para o LLM
                evidence_context = ""
                if evidence:
                    evidence_context = f"Evid√™ncias encontradas: {evidence}"
                
                llm_response = await self.llm.generate_response(
                    f"O usu√°rio perguntou: '{message}'. "
                    f"Baseado nos dados da folha de pagamento, encontrei: '{rag_data}'. "
                    f"{evidence_context} "
                    f"Transforme isso em uma resposta conversacional, natural e amig√°vel, "
                    f"como se voc√™ fosse um assistente pessoal. Use os dados encontrados mas "
                    f"seja fluido e natural na resposta.",
                    context
                )
                
                return {
                    "response": llm_response,
                    "evidence": evidence,
                    "tool_used": "rag"
                }
            except Exception as llm_error:
                logger.error(f"Erro no LLM: {llm_error}")
                # Resposta fluida sem LLM
                response = f"Perfeito! Encontrei os dados que voc√™ pediu: {rag_data} üòä"
                if evidence:
                    response += f" Os dados est√£o bem detalhados e confi√°veis!"
                response += " Precisa de mais alguma informa√ß√£o sobre folha de pagamento?"
                
                return {
                    "response": response,
                    "evidence": evidence,
                    "tool_used": "rag"
                }
            
        except Exception as e:
            logger.error(f"Erro no RAG: {e}")
            return {
                "response": f"Desculpe, n√£o consegui consultar os dados de folha no momento. Tente novamente em alguns instantes.",
                "evidence": None,
                "tool_used": "rag"
            }
    
    async def _process_web_query(self, message: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """
        Processa consulta de busca na web
        
        Args:
            message: Mensagem do usu√°rio
            context: Contexto da conversa
            
        Returns:
            Resposta processada
        """
        try:
            # Executa busca na web
            web_result = await self.web_search.search_with_citation(message)
            
            if not web_result["success"]:
                # Resposta fluida mesmo sem LLM
                response = f"Ops! N√£o consegui acessar as informa√ß√µes na web no momento. üòä Mas n√£o se preocupe! Tente novamente em alguns instantes que vou buscar para voc√™. Ou posso ajudar com outras quest√µes sobre folha de pagamento!"
                return {
                    "response": response,
                    "evidence": None,
                    "tool_used": "web"
                }
            
            # Usa LLM para tornar a resposta mais fluida e conversacional
            web_data = web_result["data"]
            evidence = web_result.get("evidence", [])
            
            try:
                # Monta contexto para o LLM
                evidence_context = ""
                if evidence:
                    evidence_context = f"Fontes encontradas: {evidence}"
                
                llm_response = await self.llm.generate_response(
                    f"O usu√°rio perguntou: '{message}'. "
                    f"Baseado na busca na web, encontrei: '{web_data}'. "
                    f"{evidence_context} "
                    f"Transforme isso em uma resposta conversacional, natural e amig√°vel, "
                    f"como se voc√™ fosse um assistente pessoal. Use as informa√ß√µes encontradas "
                    f"mas seja fluido e natural na resposta.",
                    context
                )
                
                return {
                    "response": llm_response,
                    "evidence": evidence,
                    "tool_used": "web"
                }
            except Exception as llm_error:
                logger.error(f"Erro no LLM: {llm_error}")
                # Resposta fluida sem LLM
                response = f"Perfeito! Encontrei informa√ß√µes sobre '{message}':\n\n{web_data} üòä"
                if evidence:
                    response += f"\n\nAs fontes est√£o bem detalhadas e confi√°veis!"
                response += "\n\nPrecisa de mais alguma informa√ß√£o sobre legisla√ß√£o trabalhista?"
                
                return {
                    "response": response,
                    "evidence": evidence,
                    "tool_used": "web"
                }
            
        except Exception as e:
            logger.error(f"Erro na busca web: {e}")
            return {
                "response": f"Desculpe, n√£o consegui buscar informa√ß√µes na web no momento. Tente novamente em alguns instantes.",
                "evidence": None,
                "tool_used": "web"
            }
    
    async def _process_general_query(self, message: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """
        Processa consulta geral
        
        Args:
            message: Mensagem do usu√°rio
            context: Contexto da conversa
            
        Returns:
            Resposta processada
        """
        try:
            # Gera resposta geral usando LLM
            response = await self.llm.generate_response(message, context)
            
            return {
                "response": response,
                "evidence": None,
                "tool_used": "general"
            }
            
        except Exception as e:
            logger.error(f"Erro na resposta geral: {e}")
            # Resposta fluida mesmo sem LLM
            message_lower = message.lower()
            
            # Sauda√ß√µes
            if any(greeting in message_lower for greeting in ['ol√°', 'oi', 'bom dia', 'boa tarde', 'boa noite', 'e a√≠', 'eae', 'como vai']):
                response = "Ol√°! üòä Estou aqui para ajudar com quest√µes de folha de pagamento. Como posso te auxiliar hoje?"
            
            # Agradecimentos
            elif any(thanks in message_lower for thanks in ['obrigado', 'obrigada', 'valeu', 'obrigad', 'brigado', 'brigada', 'valeu']):
                response = "De nada! üòä Fico feliz em poder ajudar. Precisa de mais alguma coisa sobre folha de pagamento?"
            
            # Como est√°
            elif any(how in message_lower for how in ['como voc√™ est√°', 'como est√°', 'tudo bem', 'beleza', 'tranquilo', 'suave']):
                response = "Estou √≥timo, obrigado por perguntar! üòä Pronto para ajudar com qualquer quest√£o de folha de pagamento. O que voc√™ gostaria de saber?"
            
            # Confirma√ß√µes
            elif any(confirm in message_lower for confirm in ['ok', 'certo', 'entendi', 'perfeito', 'legal', 'bacana', 'show', 'massa', 'top']):
                response = "Perfeito! üòä Estou aqui para ajudar com qualquer quest√£o de folha de pagamento. O que voc√™ gostaria de saber?"
            
            # Despedidas
            elif any(bye in message_lower for bye in ['tchau', 'at√© logo', 'at√© mais', 'at√©', 'falou', 'flw', 'abra√ßo', 'abra√ßos']):
                response = "At√© logo! üòä Foi um prazer ajudar. Volte sempre que precisar de informa√ß√µes sobre folha de pagamento!"
            
            # Perguntas sobre o que pode fazer
            elif any(what in message_lower for what in ['o que voc√™ faz', 'o que voc√™ pode', 'como voc√™ pode', 'o que consegue', 'o que sabe']):
                response = "Posso ajudar com v√°rias coisas! üòä Consultar dados de folha de pagamento, buscar informa√ß√µes sobre legisla√ß√£o trabalhista, e conversar sobre qualquer assunto relacionado. O que voc√™ gostaria de saber?"
            
            # Perguntas sobre ajuda
            elif any(help in message_lower for help in ['ajuda', 'help', 'pode ajudar', 'consegue ajudar', 'preciso de ajuda']):
                response = "Claro que posso ajudar! üòä Posso consultar dados de folha de pagamento, buscar informa√ß√µes sobre legisla√ß√£o trabalhista, e responder qualquer pergunta relacionada. O que voc√™ gostaria de saber?"
            
            # Perguntas sobre d√∫vidas
            elif any(doubt in message_lower for doubt in ['d√∫vida', 'duvida', 'duvido', 'pergunta', 'quest√£o', 'questao', 'problema']):
                response = "Estou aqui para esclarecer suas d√∫vidas! üòä Posso ajudar com quest√µes de folha de pagamento, legisla√ß√£o trabalhista, ou qualquer outra pergunta. O que voc√™ gostaria de saber?"
            
            # Conversas sobre lembrar
            elif any(remember in message_lower for remember in ['lembra', 'lembro', 'lembrar', 'esqueci', 'esqueceu', 'esquecer']):
                response = "Sim, lembro! üòä Estou aqui para ajudar com qualquer quest√£o de folha de pagamento. O que voc√™ gostaria de saber?"
            
            # Conversas sobre saber/conhecer
            elif any(know in message_lower for know in ['sabia', 'sabe', 'saber', 'conhece', 'conhecer', 'conhecia']):
                response = "Sim, sei v√°rias coisas! üòä Posso ajudar com dados de folha de pagamento, legisla√ß√£o trabalhista, e muito mais. O que voc√™ gostaria de saber?"
            
            # Conversas sobre poder/conseguir
            elif any(can in message_lower for can in ['pode', 'poder', 'consegue', 'conseguir', 'quero', 'quer', 'querer', 'preciso', 'precisa', 'precisar', 'gostaria']):
                response = "Claro que posso! üòä Estou aqui para ajudar com qualquer quest√£o de folha de pagamento. O que voc√™ gostaria de saber?"
            
            # Conversas sobre falar/conversar
            elif any(talk in message_lower for talk in ['conversa', 'falar', 'falei', 'disse', 'comentou', 'mencionou']):
                response = "Adoro conversar! üòä Estou aqui para ajudar com qualquer quest√£o de folha de pagamento. O que voc√™ gostaria de saber?"
            
            # Resposta padr√£o para qualquer outra coisa
            else:
                response = "Entendi! üòä Posso ajudar com consultas sobre dados de folha de pagamento, informa√ß√µes sobre funcion√°rios, ou quest√µes gerais sobre legisla√ß√£o trabalhista. O que voc√™ gostaria de saber?"
            
            return {
                "response": response,
                "evidence": None,
                "tool_used": "general"
            }
    
    
    def get_session_stats(self) -> Dict[str, Any]:
        """Obt√©m estat√≠sticas das sess√µes"""
        return self.memory.get_session_stats()
    
    def get_context_summary(self, session_id: str) -> Dict[str, Any]:
        """Obt√©m resumo do contexto da sess√£o"""
        return self.memory.get_context_summary(session_id)
    
    def cleanup_sessions(self):
        """Limpa sess√µes expiradas"""
        self.memory.cleanup_old_sessions()
    